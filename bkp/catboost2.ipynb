{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar Librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Uso librería sklearn.metrics **\n",
    "\n",
    "- recall_score: Calcula el recall (sensibilidad), que mide la proporción de verdaderos positivos detectados por el modelo.\n",
    "- f1_score: Calcula el F1 Score, que es la media armónica de la precisión y el recall.\n",
    "- roc_auc_score: Mide el Área Bajo la Curva (AUC) ROC, que es una métrica de rendimiento para la clasificación binaria en diferentes umbrales de clasificación.\n",
    "\n",
    "** Medias que podrian nos interesar (Analisar)**\n",
    "- accuracy_score: Calcula la precisión del modelo, que es la proporción de predicciones correctas entre el número total de predicciones.\n",
    "- precision_score: Calcula la precisión, que es la proporción de verdaderos positivos entre el total de positivos predichos. Útil para ver cuántas de las predicciones positivas son realmente positivas.\n",
    "- classification_report: Proporciona un resumen de las principales métricas de clasificación como precisión, recall, F1 Score, etc., para cada clase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#from sklearn.metrics import recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar datos en formato CSV para ENTRENAMIENTO, VALIDACION y TEST "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importancia de Cada Conjunto:**\n",
    "\n",
    "- **Conjunto de Entrenamiento:** Utilizado para ajustar los pesos del modelo. Aquí, el modelo \"aprende\" de los datos.\n",
    "- **Conjunto de Validación:** Utilizado para ajustar los hiperparámetros del modelo (como la profundidad de un árbol, la tasa de aprendizaje, el número de árboles, etc.) y para realizar la selección del modelo. Ayuda a determinar cuándo detener el entrenamiento para evitar sobreajuste.\n",
    "- **Conjunto de Test:** Proporciona una evaluación final del rendimiento del modelo. Es esencial que este conjunto no se utilice para ajustar el modelo de ninguna manera para garantizar que el resultado refleje el rendimiento en datos no vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los archivos tienen un número de filas coincidente entre características y etiquetas, y la columna objetivo es 'satisfaction'.\n"
     ]
    }
   ],
   "source": [
    "# Crear la ruta si no existe\n",
    "ruta = os.path.abspath('../data/modelos_entrenamiento/')\n",
    "\n",
    "# Datos Entrenamiento\n",
    "X_train = pd.read_csv(os.path.join(ruta, 'X_train.csv'))\n",
    "y_train = pd.read_csv(os.path.join(ruta, 'y_train.csv'))\n",
    "\n",
    "# Datos Validación\n",
    "X_val = pd.read_csv(os.path.join(ruta, 'X_val.csv'))\n",
    "y_val = pd.read_csv(os.path.join(ruta, 'y_val.csv'))\n",
    "\n",
    "# Datos Test (Prueba)\n",
    "X_test = pd.read_csv(os.path.join(ruta, 'X_test.csv'))\n",
    "y_test = pd.read_csv(os.path.join(ruta, 'y_test.csv'))\n",
    "\n",
    "# Verificar que las dimensiones de X e y coincidan para cada conjunto de datos\n",
    "assert X_train.shape[0] == y_train.shape[0], \"Error: El número de filas en X_train y y_train no coincide.\"\n",
    "assert X_val.shape[0] == y_val.shape[0], \"Error: El número de filas en X_val y y_val no coincide.\"\n",
    "assert X_test.shape[0] == y_test.shape[0], \"Error: El número de filas en X_test y y_test no coincide.\"\n",
    "\n",
    "# Verificar que las columnas tengan nombres correctos y consistentes\n",
    "assert 'satisfaction' in y_train.columns, \"Error: El archivo y_train.csv debe tener una columna llamada 'satisfaction'.\"\n",
    "assert 'satisfaction' in y_val.columns, \"Error: El archivo y_val.csv debe tener una columna llamada 'satisfaction'.\"\n",
    "assert 'satisfaction' in y_test.columns, \"Error: El archivo y_test.csv debe tener una columna llamada 'satisfaction'.\"\n",
    "\n",
    "print(\"Todos los archivos tienen un número de filas coincidente entre características y etiquetas, y la columna objetivo es 'satisfaction'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificar si las variables son numericas para evitar error al entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de datos de y_train: satisfaction    int64\n",
      "dtype: object\n",
      "Tipo de datos de y_val: satisfaction    int64\n",
      "dtype: object\n",
      "Tipo de datos de y_test: satisfaction    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Verificar tipos de datos de las etiquetas\n",
    "print(\"Tipo de datos de y_train:\", y_train.dtypes)\n",
    "print(\"Tipo de datos de y_val:\", y_val.dtypes)\n",
    "print(\"Tipo de datos de y_test:\", y_test.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separar características y etiquetas\n",
    "Hay que separar las características (X) de la variable objetivo (y) para cada dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características y etiquetas separadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Separar las características (X) de la variable objetivo (y)\n",
    "# Ya hemos cargado los archivos con solo características en X_train, X_val, X_test\n",
    "\n",
    "# Separar la variable objetivo (y) - Asumimos que y_train, y_val, y_test solo tienen la columna 'satisfaction'\n",
    "y_train = y_train['satisfaction']\n",
    "y_val = y_val['satisfaction']\n",
    "y_test = y_test['satisfaction']\n",
    "\n",
    "print(\"Características y etiquetas separadas correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializar el modelo CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5642258\ttest: 0.5643419\tbest: 0.5643419 (0)\ttotal: 14.3ms\tremaining: 7.14s\n",
      "100:\tlearn: 0.0954957\ttest: 0.1020326\tbest: 0.1020326 (100)\ttotal: 1.44s\tremaining: 5.68s\n",
      "200:\tlearn: 0.0812890\ttest: 0.0933198\tbest: 0.0933198 (200)\ttotal: 2.67s\tremaining: 3.98s\n",
      "300:\tlearn: 0.0732948\ttest: 0.0903986\tbest: 0.0903844 (299)\ttotal: 3.91s\tremaining: 2.58s\n",
      "400:\tlearn: 0.0675110\ttest: 0.0891242\tbest: 0.0891138 (378)\ttotal: 5.05s\tremaining: 1.25s\n",
      "499:\tlearn: 0.0624786\ttest: 0.0884543\tbest: 0.0884543 (499)\ttotal: 6.14s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.08845431341\n",
      "bestIteration = 499\n",
      "\n",
      "Exactitud del modelo en el conjunto de prueba: 0.96\n",
      "CatBoost - Recall en Entrenamiento: 0.96\n",
      "CatBoost - Recall en Validación: 0.94\n",
      "CatBoost - Recall en Prueba: 0.94\n",
      "CatBoost - F1 Score en Entrenamiento: 0.97\n",
      "CatBoost - F1 Score en Validación: 0.96\n",
      "CatBoost - F1 Score en Prueba: 0.96\n",
      "CatBoost - AUC en Entrenamiento: 1.00\n",
      "CatBoost - AUC en Validación: 0.99\n",
      "CatBoost - AUC en Prueba: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Inicializar el modelo CatBoostClassifier - Erika\n",
    "# Aquí se especifican los parámetros principales del modelo:\n",
    "# - iterations: número de iteraciones (árboles) a entrenar\n",
    "# - depth: profundidad de los árboles de decisión\n",
    "# - learning_rate: tasa de aprendizaje para el ajuste de los pesos\n",
    "# - verbose: cada cuántas iteraciones se imprime un resumen del progreso\n",
    "model = CatBoostClassifier(iterations=500, depth=6, learning_rate=0.1, verbose=100)\n",
    "\n",
    "# Entrenar el modelo utilizando el conjunto de entrenamiento y validación\n",
    "# El parámetro eval_set se utiliza para especificar el conjunto de validación.\n",
    "# early_stopping_rounds permite detener el entrenamiento si no hay mejora en el conjunto de validación\n",
    "model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=50)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba (test)\n",
    "# El método score devuelve la exactitud (accuracy) del modelo en el conjunto de prueba\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Exactitud del modelo en el conjunto de prueba: {accuracy:.2f}\")\n",
    "\n",
    "# Realizar predicciones en los conjuntos de entrenamiento y prueba\n",
    "# predict() devuelve las etiquetas predichas para las muestras proporcionadas\n",
    "catboost_train_preds = model.predict(X_train)\n",
    "catboost_val_preds = model.predict(X_val)\n",
    "catboost_test_preds = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Calcular las probabilidades predichas para el conjunto de entrenamiento y prueba\n",
    "# predict_proba() devuelve las probabilidades de clase; [:, 1] selecciona la probabilidad de la clase positiva\n",
    "catboost_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "catboost_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "catboost_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "# Calcular las métricas de evaluación para los conjuntos de entrenamiento y prueba\n",
    "# Recall (Sensibilidad): mide la capacidad del modelo para detectar todas las muestras positivas\n",
    "# Usamos pos_label=1 porque las etiquetas son numéricas (0 para 'neutral or dissatisfied' y 1 para 'satisfied')\n",
    "catboost_train_recall = recall_score(y_train, catboost_train_preds, pos_label=1)\n",
    "catboost_val_recall = recall_score(y_val, catboost_val_preds, pos_label=1)\n",
    "catboost_test_recall = recall_score(y_test, catboost_test_preds, pos_label=1)\n",
    "\n",
    "# F1 Score: media armónica de la precisión y la sensibilidad, útil en conjuntos de datos desbalanceados\n",
    "catboost_train_f1 = f1_score(y_train, catboost_train_preds, pos_label=1)\n",
    "catboost_val_f1 = f1_score(y_val, catboost_val_preds, pos_label=1)\n",
    "catboost_test_f1 = f1_score(y_test, catboost_test_preds, pos_label=1)\n",
    "\n",
    "# AUC (Area Under the Curve): mide la capacidad del modelo para distinguir entre clases\n",
    "# No es necesario mapear las etiquetas ya que y_train y y_test son numéricas\n",
    "catboost_train_auc = roc_auc_score(y_train, catboost_train_proba)\n",
    "catboost_val_auc = roc_auc_score(y_val, catboost_val_proba)\n",
    "catboost_test_auc = roc_auc_score(y_test, catboost_test_proba)\n",
    "\n",
    "# Imprimir las métricas de evaluación para analizar el rendimiento del modelo\n",
    "print(f\"CatBoost - Recall en Entrenamiento: {catboost_train_recall:.2f}\")\n",
    "print(f\"CatBoost - Recall en Validación: {catboost_val_recall:.2f}\")\n",
    "print(f\"CatBoost - Recall en Prueba: {catboost_test_recall:.2f}\")\n",
    "\n",
    "print(f\"CatBoost - F1 Score en Entrenamiento: {catboost_train_f1:.2f}\")\n",
    "print(f\"CatBoost - F1 Score en Validación: {catboost_val_f1:.2f}\")\n",
    "print(f\"CatBoost - F1 Score en Prueba: {catboost_test_f1:.2f}\")\n",
    "\n",
    "print(f\"CatBoost - AUC en Entrenamiento: {catboost_train_auc:.2f}\")\n",
    "print(f\"CatBoost - AUC en Validación: {catboost_val_auc:.2f}\")\n",
    "print(f\"CatBoost - AUC en Prueba: {catboost_test_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular métricas para el conjunto de validación\n",
    "val_accuracy = accuracy_score(y_val, catboost_val_preds)\n",
    "val_precision = precision_score(y_val, catboost_val_preds, pos_label=1)\n",
    "val_recall = recall_score(y_val, catboost_val_preds, pos_label=1)\n",
    "val_f1 = f1_score(y_val, catboost_val_preds, pos_label=1)\n",
    "val_auc = roc_auc_score(y_val, catboost_val_proba)\n",
    "\n",
    "# Calcular métricas para el conjunto de prueba\n",
    "test_accuracy = accuracy_score(y_test, catboost_test_preds)\n",
    "test_precision = precision_score(y_test, catboost_test_preds, pos_label=1)\n",
    "test_recall = recall_score(y_test, catboost_test_preds, pos_label=1)\n",
    "test_f1 = f1_score(y_test, catboost_test_preds, pos_label=1)\n",
    "test_auc = roc_auc_score(y_test, catboost_test_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost - AUC en Entrenamiento: 1.00\n",
      "Reporte de Clasificación en Entrenamiento:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     35261\n",
      "           1       0.98      0.96      0.97     26895\n",
      "\n",
      "    accuracy                           0.98     62156\n",
      "   macro avg       0.98      0.97      0.98     62156\n",
      "weighted avg       0.98      0.98      0.98     62156\n",
      "\n",
      "CatBoost - AUC en Validación: 0.99\n",
      "Reporte de Clasificación en Validación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     11781\n",
      "           1       0.97      0.94      0.96      8938\n",
      "\n",
      "    accuracy                           0.96     20719\n",
      "   macro avg       0.96      0.96      0.96     20719\n",
      "weighted avg       0.96      0.96      0.96     20719\n",
      "\n",
      "CatBoost - AUC en Prueba: 1.00\n",
      "Reporte de Clasificación en Prueba:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     11655\n",
      "           1       0.97      0.94      0.96      9064\n",
      "\n",
      "    accuracy                           0.96     20719\n",
      "   macro avg       0.97      0.96      0.96     20719\n",
      "weighted avg       0.96      0.96      0.96     20719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprimir métricas para el conjunto de entrenamiento\n",
    "print(f\"CatBoost - AUC en Entrenamiento: {train_auc:.2f}\")\n",
    "print(\"Reporte de Clasificación en Entrenamiento:\\n\", train_report)\n",
    "\n",
    "# Imprimir métricas para el conjunto de validación\n",
    "print(f\"CatBoost - AUC en Validación: {val_auc:.2f}\")\n",
    "print(\"Reporte de Clasificación en Validación:\\n\", val_report)\n",
    "\n",
    "# Imprimir métricas para el conjunto de prueba\n",
    "print(f\"CatBoost - AUC en Prueba: {test_auc:.2f}\")\n",
    "print(\"Reporte de Clasificación en Prueba:\\n\", test_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Legenda**\n",
    "\n",
    "- Support (Soporte) indica cuántas instancias del conjunto de datos pertenecen a cada clase.\n",
    "Esta métrica no depende de las predicciones del modelo, sino de la distribución real de las clases en los datos de evaluación.\n",
    "\n",
    "- Precisión (Precision): mide la proporción de verdaderos positivos (TP) entre el total de predicciones positivas (es decir, la suma de verdaderos positivos y falsos positivos). En otras palabras, de todas las instancias que el modelo predice como positivas, ¿cuántas realmente lo son?\n",
    "\n",
    "- Recall (también conocido como sensibilidad o exhaustividad): mide la capacidad del modelo para identificar correctamente todas las instancias positivas en el conjunto de datos.\n",
    "\n",
    "    **Interpretación:**\n",
    "\n",
    "    - El recall responde a la pregunta: De todas las instancias que son realmente positivas, ¿cuántas fueron correctamente identificadas por el modelo?\n",
    "    Un recall alto indica que el modelo está capturando la mayoría de los verdaderos positivos y, por lo tanto, tiene pocos falsos negativos.\n",
    "    ​\n",
    "    - F1-score es la media armónica de la precisión (precision) y el recall. Combina ambas métricas en un solo valor, balanceando la importancia de tener pocos falsos positivos y pocos falsos negativos.\n",
    "\n",
    "- macro avg:\n",
    "    - Útil para obtener una visión general del rendimiento del modelo en todas las clases sin considerar el tamaño de la clase.\n",
    "    - Ideal cuando todas las clases tienen igual importancia y deseas evaluar el rendimiento de cada clase por igual.\n",
    "    - Puede destacar problemas en clases minoritarias, ya que no se ve influenciado por el tamaño de la clase.\n",
    "\n",
    "- weighted avg:\n",
    "    - Proporciona un promedio ponderado basado en el número de instancias por clase.\n",
    "    - Ideal para conjuntos de datos desbalanceados, ya que refleja más fielmente el rendimiento del modelo en función de la distribución de clases.\n",
    "    - Es útil cuando algunas clases son más frecuentes que otras y deseas que esto se refleje en la evaluación del modelo.  \n",
    "\n",
    "    - En resumen (macro avg / weigthted avg)\n",
    "        - Si tienes un problema de clasificación con un conjunto de datos desbalanceado (por ejemplo, más clientes insatisfechos que satisfechos):\n",
    "        - macro avg te dará una idea de cómo tu modelo se desempeña en promedio en ambas clases, tratándolas por igual.\n",
    "        - weighted avg te proporcionará una métrica más cercana al rendimiento global del modelo considerando el desbalance, dándote una imagen más realista de cómo se comportará el modelo en producción donde algunas clases son más comunes que otras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarda el modelo CatBoost entrenado para ser usado en Streamlit (No sacar esta linea de codigo)\n",
    "model.save_model('../data/modelos_entrenamiento/catboost_model.cbm')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
