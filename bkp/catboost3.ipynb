{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los archivos tienen un número de filas coincidente entre características y etiquetas, y la columna objetivo es 'satisfaction'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Especificar la ruta a la carpeta que contiene los archivos CSV\n",
    "ruta = os.path.abspath('../data/modelos_entrenamiento/')\n",
    "\n",
    "# Cargar los datos desde los archivos CSV en DataFrames\n",
    "X_train = pd.read_csv(os.path.join(ruta, 'X_train.csv'))\n",
    "y_train = pd.read_csv(os.path.join(ruta, 'y_train.csv'))\n",
    "X_val = pd.read_csv(os.path.join(ruta, 'X_val.csv'))\n",
    "y_val = pd.read_csv(os.path.join(ruta, 'y_val.csv'))\n",
    "X_test = pd.read_csv(os.path.join(ruta, 'X_test.csv'))\n",
    "y_test = pd.read_csv(os.path.join(ruta, 'y_test.csv'))\n",
    "\n",
    "# Verificar que las dimensiones de X e y coincidan para cada conjunto de datos\n",
    "assert X_train.shape[0] == y_train.shape[0], \"Error: El número de filas en X_train y y_train no coincide.\"\n",
    "assert X_val.shape[0] == y_val.shape[0], \"Error: El número de filas en X_val y y_val no coincide.\"\n",
    "assert X_test.shape[0] == y_test.shape[0], \"Error: El número de filas en X_test y y_test no coincide.\"\n",
    "\n",
    "# Verificar que las columnas tengan nombres correctos y consistentes\n",
    "assert 'satisfaction' in y_train.columns, \"Error: El archivo y_train.csv debe tener una columna llamada 'satisfaction'.\"\n",
    "assert 'satisfaction' in y_val.columns, \"Error: El archivo y_val.csv debe tener una columna llamada 'satisfaction'.\"\n",
    "assert 'satisfaction' in y_test.columns, \"Error: El archivo y_test.csv debe tener una columna llamada 'satisfaction'.\"\n",
    "\n",
    "print(\"Todos los archivos tienen un número de filas coincidente entre características y etiquetas, y la columna objetivo es 'satisfaction'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características y etiquetas separadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Separar las características (X) de la variable objetivo (y)\n",
    "# Aquí asumimos que X_train, X_val, y X_test ya son DataFrames que contienen solo las características\n",
    "# Si estos DataFrames incluyen la columna 'satisfaction', habría que eliminarla.\n",
    "\n",
    "# Separar la variable objetivo (y)\n",
    "y_train = y_train['satisfaction']\n",
    "y_val = y_val['satisfaction']\n",
    "y_test = y_test['satisfaction']\n",
    "\n",
    "print(\"Características y etiquetas separadas correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de datos de y_train: int64\n",
      "Tipo de datos de y_val: int64\n",
      "Tipo de datos de y_test: int64\n",
      "Tipos de datos después de la conversión:\n",
      "Tipo de datos de y_train: int64\n",
      "Tipo de datos de y_val: int64\n",
      "Tipo de datos de y_test: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar tipos de datos de las etiquetas\n",
    "print(\"Tipo de datos de y_train:\", y_train.dtypes)\n",
    "print(\"Tipo de datos de y_val:\", y_val.dtypes)\n",
    "print(\"Tipo de datos de y_test:\", y_test.dtypes)\n",
    "\n",
    "# Convertir las etiquetas a números (si es necesario)\n",
    "# Este paso solo se ejecutará si las etiquetas no son numéricas\n",
    "y_train = pd.to_numeric(y_train, errors='coerce')\n",
    "y_val = pd.to_numeric(y_val, errors='coerce')\n",
    "y_test = pd.to_numeric(y_test, errors='coerce')\n",
    "\n",
    "# Confirmar la conversión\n",
    "print(\"Tipos de datos después de la conversión:\")\n",
    "print(\"Tipo de datos de y_train:\", y_train.dtypes)\n",
    "print(\"Tipo de datos de y_val:\", y_val.dtypes)\n",
    "print(\"Tipo de datos de y_test:\", y_test.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5642258\ttest: 0.5643419\tbest: 0.5643419 (0)\ttotal: 12ms\tremaining: 5.99s\n",
      "100:\tlearn: 0.0954957\ttest: 0.1020326\tbest: 0.1020326 (100)\ttotal: 1.4s\tremaining: 5.52s\n",
      "200:\tlearn: 0.0812890\ttest: 0.0933198\tbest: 0.0933198 (200)\ttotal: 3.06s\tremaining: 4.56s\n",
      "300:\tlearn: 0.0732948\ttest: 0.0903986\tbest: 0.0903844 (299)\ttotal: 4.28s\tremaining: 2.83s\n",
      "400:\tlearn: 0.0675110\ttest: 0.0891242\tbest: 0.0891138 (378)\ttotal: 5.46s\tremaining: 1.35s\n",
      "499:\tlearn: 0.0624786\ttest: 0.0884543\tbest: 0.0884543 (499)\ttotal: 6.64s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.08845431341\n",
      "bestIteration = 499\n",
      "\n",
      "Exactitud del modelo en el conjunto de prueba: 0.96\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Inicializar el modelo CatBoostClassifier\n",
    "model = CatBoostClassifier(iterations=500, depth=6, learning_rate=0.1, verbose=100)\n",
    "\n",
    "# Entrenar el modelo utilizando el conjunto de entrenamiento y validación\n",
    "model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=50)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba (test)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Exactitud del modelo en el conjunto de prueba: {accuracy:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost - Recall en Entrenamiento: 0.96\n",
      "CatBoost - Recall en Prueba: 0.94\n",
      "CatBoost - F1 Score en Entrenamiento: 0.97\n",
      "CatBoost - F1 Score en Prueba: 0.96\n",
      "CatBoost - AUC en Entrenamiento: 1.00\n",
      "CatBoost - AUC en Prueba: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Realizar predicciones en los conjuntos de entrenamiento y prueba\n",
    "catboost_train_preds = model.predict(X_train)\n",
    "catboost_test_preds = model.predict(X_test)\n",
    "\n",
    "# Calcular las probabilidades predichas para el conjunto de entrenamiento y prueba\n",
    "catboost_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "catboost_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcular las métricas de evaluación para los conjuntos de entrenamiento y prueba\n",
    "catboost_train_recall = recall_score(y_train, catboost_train_preds)\n",
    "catboost_test_recall = recall_score(y_test, catboost_test_preds)\n",
    "\n",
    "catboost_train_f1 = f1_score(y_train, catboost_train_preds)\n",
    "catboost_test_f1 = f1_score(y_test, catboost_test_preds)\n",
    "\n",
    "catboost_train_auc = roc_auc_score(y_train, catboost_train_proba)\n",
    "catboost_test_auc = roc_auc_score(y_test, catboost_test_proba)\n",
    "\n",
    "# Imprimir las métricas de evaluación para analizar el rendimiento del modelo\n",
    "print(f\"CatBoost - Recall en Entrenamiento: {catboost_train_recall:.2f}\")\n",
    "print(f\"CatBoost - Recall en Prueba: {catboost_test_recall:.2f}\")\n",
    "print(f\"CatBoost - F1 Score en Entrenamiento: {catboost_train_f1:.2f}\")\n",
    "print(f\"CatBoost - F1 Score en Prueba: {catboost_test_f1:.2f}\")\n",
    "print(f\"CatBoost - AUC en Entrenamiento: {catboost_train_auc:.2f}\")\n",
    "print(f\"CatBoost - AUC en Prueba: {catboost_test_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Métricas para el Conjunto de Entrenamiento ---\n",
      "Exactitud en Entrenamiento: 0.98\n",
      "Precisión en Entrenamiento: 0.98\n",
      "Recall en Entrenamiento: 0.96\n",
      "F1 Score en Entrenamiento: 0.97\n",
      "AUC en Entrenamiento: 1.00\n",
      "Reporte de Clasificación en Entrenamiento:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     35261\n",
      "           1       0.98      0.96      0.97     26895\n",
      "\n",
      "    accuracy                           0.98     62156\n",
      "   macro avg       0.98      0.97      0.98     62156\n",
      "weighted avg       0.98      0.98      0.98     62156\n",
      "\n",
      "--- Métricas para el Conjunto de Validación ---\n",
      "Exactitud en Validación: 0.96\n",
      "Precisión en Validación: 0.97\n",
      "Recall en Validación: 0.94\n",
      "F1 Score en Validación: 0.96\n",
      "AUC en Validación: 0.99\n",
      "Reporte de Clasificación en Validación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     11781\n",
      "           1       0.97      0.94      0.96      8938\n",
      "\n",
      "    accuracy                           0.96     20719\n",
      "   macro avg       0.96      0.96      0.96     20719\n",
      "weighted avg       0.96      0.96      0.96     20719\n",
      "\n",
      "--- Métricas para el Conjunto de Prueba ---\n",
      "Exactitud en Prueba: 0.96\n",
      "Precisión en Prueba: 0.97\n",
      "Recall en Prueba: 0.94\n",
      "F1 Score en Prueba: 0.96\n",
      "AUC en Prueba: 1.00\n",
      "Reporte de Clasificación en Prueba:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     11655\n",
      "           1       0.97      0.94      0.96      9064\n",
      "\n",
      "    accuracy                           0.96     20719\n",
      "   macro avg       0.97      0.96      0.96     20719\n",
      "weighted avg       0.96      0.96      0.96     20719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importar las funciones necesarias desde sklearn.metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "# Realizar predicciones en los conjuntos de entrenamiento, validación y prueba\n",
    "catboost_train_preds = model.predict(X_train)\n",
    "catboost_val_preds = model.predict(X_val)\n",
    "catboost_test_preds = model.predict(X_test)\n",
    "\n",
    "# Calcular las probabilidades predichas para los conjuntos de entrenamiento, validación y prueba\n",
    "catboost_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "catboost_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "catboost_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcular métricas para el conjunto de entrenamiento\n",
    "train_accuracy = accuracy_score(y_train, catboost_train_preds)\n",
    "train_precision = precision_score(y_train, catboost_train_preds, pos_label=1)\n",
    "train_recall = recall_score(y_train, catboost_train_preds, pos_label=1)\n",
    "train_f1 = f1_score(y_train, catboost_train_preds, pos_label=1)\n",
    "train_auc = roc_auc_score(y_train, catboost_train_proba)\n",
    "train_report = classification_report(y_train, catboost_train_preds)\n",
    "\n",
    "# Calcular métricas para el conjunto de validación\n",
    "val_accuracy = accuracy_score(y_val, catboost_val_preds)\n",
    "val_precision = precision_score(y_val, catboost_val_preds, pos_label=1)\n",
    "val_recall = recall_score(y_val, catboost_val_preds, pos_label=1)\n",
    "val_f1 = f1_score(y_val, catboost_val_preds, pos_label=1)\n",
    "val_auc = roc_auc_score(y_val, catboost_val_proba)\n",
    "val_report = classification_report(y_val, catboost_val_preds)\n",
    "\n",
    "# Calcular métricas para el conjunto de prueba\n",
    "test_accuracy = accuracy_score(y_test, catboost_test_preds)\n",
    "test_precision = precision_score(y_test, catboost_test_preds, pos_label=1)\n",
    "test_recall = recall_score(y_test, catboost_test_preds, pos_label=1)\n",
    "test_f1 = f1_score(y_test, catboost_test_preds, pos_label=1)\n",
    "test_auc = roc_auc_score(y_test, catboost_test_proba)\n",
    "test_report = classification_report(y_test, catboost_test_preds)\n",
    "\n",
    "# Imprimir métricas para el conjunto de entrenamiento\n",
    "print(f\"--- Métricas para el Conjunto de Entrenamiento ---\")\n",
    "print(f\"Exactitud en Entrenamiento: {train_accuracy:.2f}\")\n",
    "print(f\"Precisión en Entrenamiento: {train_precision:.2f}\")\n",
    "print(f\"Recall en Entrenamiento: {train_recall:.2f}\")\n",
    "print(f\"F1 Score en Entrenamiento: {train_f1:.2f}\")\n",
    "print(f\"AUC en Entrenamiento: {train_auc:.2f}\")\n",
    "print(\"Reporte de Clasificación en Entrenamiento:\\n\", train_report)\n",
    "\n",
    "# Imprimir métricas para el conjunto de validación\n",
    "print(f\"--- Métricas para el Conjunto de Validación ---\")\n",
    "print(f\"Exactitud en Validación: {val_accuracy:.2f}\")\n",
    "print(f\"Precisión en Validación: {val_precision:.2f}\")\n",
    "print(f\"Recall en Validación: {val_recall:.2f}\")\n",
    "print(f\"F1 Score en Validación: {val_f1:.2f}\")\n",
    "print(f\"AUC en Validación: {val_auc:.2f}\")\n",
    "print(\"Reporte de Clasificación en Validación:\\n\", val_report)\n",
    "\n",
    "# Imprimir métricas para el conjunto de prueba\n",
    "print(f\"--- Métricas para el Conjunto de Prueba ---\")\n",
    "print(f\"Exactitud en Prueba: {test_accuracy:.2f}\")\n",
    "print(f\"Precisión en Prueba: {test_precision:.2f}\")\n",
    "print(f\"Recall en Prueba: {test_recall:.2f}\")\n",
    "print(f\"F1 Score en Prueba: {test_f1:.2f}\")\n",
    "print(f\"AUC en Prueba: {test_auc:.2f}\")\n",
    "print(\"Reporte de Clasificación en Prueba:\\n\", test_report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
