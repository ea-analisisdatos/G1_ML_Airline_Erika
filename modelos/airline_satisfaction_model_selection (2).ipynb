{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 'modelos_entrenados' creada o ya existente.\n",
      "\n",
      "Evaluando Random Forest...\n",
      "\n",
      "Evaluando XGBoost...\n",
      "\n",
      "Evaluando CatBoost...\n",
      "\n",
      "Evaluando Stacking...\n"
     ]
    }
   ],
   "source": [
    "# Librerías principales para manipulación de datos\n",
    "import pandas as pd  # Manejo de datos en formato tabular (DataFrames)\n",
    "import numpy as np  # Funciones matemáticas y operaciones con arrays\n",
    "import sqlite3  # Para conectarse a la base de datos SQLite\n",
    "from datetime import datetime, timedelta  # Para obtener la fecha y hora actual\n",
    "import os  # Para manejar el sistema de archivos\n",
    "import joblib  # Para guardar y cargar modelos entrenados\n",
    "import time  # Para medir el tiempo de procesamiento\n",
    "\n",
    "# Librerías para construir pipelines y preprocesamiento\n",
    "from sklearn.pipeline import Pipeline  # Para crear pipelines que incluyan pasos de preprocesamiento y modelo\n",
    "from sklearn.preprocessing import StandardScaler  # Para escalar variables numéricas\n",
    "from sklearn.compose import ColumnTransformer  # Para aplicar diferentes transformaciones a diferentes tipos de columnas\n",
    "\n",
    "# Modelos de machine learning\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier  # Algoritmo de clasificación basado en árboles y Stacking\n",
    "from xgboost import XGBClassifier  # Algoritmo XGBoost, un modelo de boosting eficiente\n",
    "from catboost import CatBoostClassifier  # Algoritmo CatBoost, un modelo de boosting que maneja variables categóricas internamente\n",
    "\n",
    "# Librerías para validación cruzada y evaluación de modelos\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold  # Validación cruzada y división estratificada de los datos\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score  # Métricas para evaluar el rendimiento de los modelos\n",
    "\n",
    "# Configuración cuaderno Jupyter: Mostrar todas las columnas y ajustar ancho de las columnas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Función para conectar a la base de datos\n",
    "def connect_db():\n",
    "    try:\n",
    "        conn = sqlite3.connect('../data/database/airline_satisfaction.db')\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"Error al conectar a la base de datos: {e}\")\n",
    "        return None\n",
    "\n",
    "# Función para crear la tabla si no existe\n",
    "def create_table():\n",
    "    conn = connect_db()\n",
    "    if conn:\n",
    "        try:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS modelos_entrenados (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                modelo TEXT,\n",
    "                accuracy_mean REAL,\n",
    "                precision_mean REAL,\n",
    "                recall_mean REAL,\n",
    "                f1_mean REAL,\n",
    "                roc_auc_mean REAL,\n",
    "                tiempo_procesamiento TEXT,\n",
    "                archivo_modelo TEXT,\n",
    "                n_estimators_catboost INTEGER,\n",
    "                depth_catboost INTEGER,\n",
    "                learning_rate_catboost REAL,\n",
    "                n_estimators_rf INTEGER,\n",
    "                n_estimators_xgb INTEGER,\n",
    "                depth_xgb INTEGER,\n",
    "                learning_rate_xgb REAL,\n",
    "                fecha_entrenamiento TEXT\n",
    "            )\n",
    "            ''')\n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "            print(\"Tabla 'modelos_entrenados' creada o ya existente.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al crear la tabla: {e}\")\n",
    "\n",
    "# Función para insertar datos en la nueva tabla\n",
    "def insertar_modelo(modelo_nombre, accuracy, precision, recall, f1, roc_auc, tiempo, archivo, \n",
    "                    n_estimators_catboost=None, depth_catboost=None, learning_rate_catboost=None, \n",
    "                    n_estimators_rf=None, n_estimators_xgb=None, depth_xgb=None, learning_rate_xgb=None):\n",
    "    conn = connect_db()\n",
    "    if conn:\n",
    "        try:\n",
    "            cursor = conn.cursor()\n",
    "            fecha_actual = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            cursor.execute('''\n",
    "                INSERT INTO modelos_entrenados \n",
    "                (modelo, accuracy_mean, precision_mean, recall_mean, f1_mean, roc_auc_mean, \n",
    "                tiempo_procesamiento, archivo_modelo, n_estimators_catboost, depth_catboost, \n",
    "                learning_rate_catboost, n_estimators_rf, n_estimators_xgb, depth_xgb, \n",
    "                learning_rate_xgb, fecha_entrenamiento)\n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            ''', (modelo_nombre, accuracy, precision, recall, f1, roc_auc, tiempo, archivo, \n",
    "                  n_estimators_catboost, depth_catboost, learning_rate_catboost, n_estimators_rf, \n",
    "                  n_estimators_xgb, depth_xgb, learning_rate_xgb, fecha_actual))\n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Error al insertar datos: {e}\")\n",
    "\n",
    "# Crear la tabla (si no existe) antes de comenzar la evaluación de modelos\n",
    "create_table()\n",
    "\n",
    "# Paso 1: Cargar los datos (CSV limpio)\n",
    "data = pd.read_csv('../data/airline_passenger_satisfaction.csv')\n",
    "\n",
    "# Paso 1.1: Eliminar registros con valores nulos en la columna 'Arrival Delay in Minutes'\n",
    "data = data.dropna(subset=['Arrival Delay in Minutes'])\n",
    "\n",
    "# Paso 1.2: Eliminar las columnas 'Unnamed: 0' y 'id' porque no aportan valor al análisis\n",
    "data = data.drop(['Unnamed: 0', 'id'], axis=1)\n",
    "\n",
    "# Paso 1.3: Convertir las etiquetas de 'satisfaction' de cadenas a valores numéricos (0 y 1)\n",
    "data['satisfaction'] = data['satisfaction'].map({'satisfied': 1, 'neutral or dissatisfied': 0})\n",
    "y = data['satisfaction']\n",
    "X = data.drop('satisfaction', axis=1)\n",
    "\n",
    "# Paso 2: Codificar manualmente las variables categóricas usando `map`\n",
    "categorical_cols = ['Gender', 'Customer Type', 'Type of Travel', 'Class']\n",
    "\n",
    "categorical_mappings = {\n",
    "    'Gender': {'Male': 0, 'Female': 1},\n",
    "    'Customer Type': {'Loyal Customer': 1, 'disloyal Customer': 0},\n",
    "    'Type of Travel': {'Business travel': 1, 'Personal Travel': 0},\n",
    "    'Class': {'Eco': 0, 'Eco Plus': 1, 'Business': 2}\n",
    "}\n",
    "\n",
    "for col, mapping in categorical_mappings.items():\n",
    "    X[col] = X[col].map(mapping)\n",
    "\n",
    "ordinal_cols = ['Inflight wifi service', 'Departure/Arrival time convenient', 'Ease of Online booking', 'Gate location', \n",
    "                'Food and drink', 'Online boarding', 'Seat comfort', 'Inflight entertainment', 'On-board service', \n",
    "                'Leg room service', 'Baggage handling', 'Checkin service', 'Inflight service', 'Cleanliness']\n",
    "\n",
    "numerical_cols = ['Age', 'Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes']\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Paso 4: Crear los pipelines específicos de cada modelo\n",
    "pipeline_rf = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_xgb = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "pipeline_catboost = Pipeline(steps=[\n",
    "    ('model', CatBoostClassifier(iterations=100, depth=6, learning_rate=0.1, verbose=False))\n",
    "])\n",
    "\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('catboost', pipeline_catboost),\n",
    "        ('xgboost', pipeline_xgb),\n",
    "        ('random_forest', pipeline_rf)\n",
    "    ],\n",
    "    final_estimator=RandomForestClassifier(n_estimators=50, random_state=42),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "def evaluar_modelo_con_tiempo(pipeline, X, y, cv):\n",
    "    start_time = time.time()\n",
    "    cv_results = cross_validate(pipeline, X, y, cv=cv, scoring=scoring, return_train_score=False)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_time_readable = str(timedelta(seconds=elapsed_time))\n",
    "    \n",
    "    return cv_results, elapsed_time, elapsed_time_readable\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "resultados = []\n",
    "\n",
    "modelos = {\n",
    "    'Random Forest': pipeline_rf,\n",
    "    'XGBoost': pipeline_xgb,\n",
    "    'CatBoost': pipeline_catboost,\n",
    "    'Stacking': stacking_model\n",
    "}\n",
    "\n",
    "for nombre_modelo, modelo in modelos.items():\n",
    "    print(f\"\\nEvaluando {nombre_modelo}...\")\n",
    "    cv_resultados, tiempo, tiempo_legible = evaluar_modelo_con_tiempo(modelo, X, y, kf)\n",
    "    \n",
    "    resultados.append({\n",
    "        'modelo': nombre_modelo,\n",
    "        'accuracy_mean': cv_resultados['test_accuracy'].mean(),\n",
    "        'precision_mean': cv_resultados['test_precision'].mean(),\n",
    "        'recall_mean': cv_resultados['test_recall'].mean(),\n",
    "        'f1_mean': cv_resultados['test_f1'].mean(),\n",
    "        'roc_auc_mean': cv_resultados['test_roc_auc'].mean(),\n",
    "        'tiempo_procesamiento': tiempo,\n",
    "        'tiempo_procesamiento_legible': tiempo_legible,\n",
    "        'modelo_pipeline': modelo\n",
    "    })\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "df_vista_consola = df_resultados.drop(columns=['modelo_pipeline'])\n",
    "\n",
    "print(\"\\nResultados finales:\")\n",
    "print(tabulate(df_vista_consola, headers='keys', tablefmt='psql'))\n",
    "\n",
    "output_csv = '../data/modelos_entrenamiento/resultados_modelos_completos.csv'\n",
    "df_resultados.to_csv(output_csv, index=False)\n",
    "print(f\"\\nLos resultados completos se han guardado en el archivo: {output_csv}\")\n",
    "\n",
    "mejor_modelo = df_resultados.loc[df_resultados['accuracy_mean'].idxmax()]\n",
    "\n",
    "print(f\"\\nEl mejor modelo ha sido: {mejor_modelo['modelo']} debido a su mejor rendimiento en accuracy de {mejor_modelo['accuracy_mean']:.4f}\")\n",
    "print(f\"\\nEntrenando el mejor modelo: {mejor_modelo['modelo']} con todos los datos...\")\n",
    "\n",
    "modelo_final = mejor_modelo['modelo_pipeline']\n",
    "modelo_final.fit(X, y)\n",
    "\n",
    "accuracy = mejor_modelo['accuracy_mean']\n",
    "precision = mejor_modelo['precision_mean']\n",
    "recall = mejor_modelo['recall_mean']\n",
    "f1 = mejor_modelo['f1_mean']\n",
    "roc_auc = mejor_modelo['roc_auc_mean']\n",
    "tiempo_procesamiento = mejor_modelo['tiempo_procesamiento_legible']\n",
    "archivo_modelo = \"\"\n",
    "\n",
    "def guardar_modelo_con_nombre(modelo, nombre_modelo):\n",
    "    output_dir = '../data/modelos_entrenamiento/'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    fecha_hora_actual = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    if nombre_modelo == 'CatBoost':\n",
    "        archivo_modelo = f\"{nombre_modelo}_mejor_modelo_{fecha_hora_actual}.cbm\"\n",
    "        modelo.named_steps['model'].save_model(os.path.join(output_dir, archivo_modelo))\n",
    "        print(f\"Modelo CatBoost guardado exitosamente con el nombre: {archivo_modelo}\")\n",
    "    else:\n",
    "        archivo_modelo = f\"{nombre_modelo}_mejor_modelo_{fecha_hora_actual}.pkl\"\n",
    "        joblib.dump(modelo, os.path.join(output_dir, archivo_modelo))\n",
    "        print(f\"Modelo guardado exitosamente con el nombre: {archivo_modelo}\")\n",
    "    \n",
    "    return archivo_modelo\n",
    "\n",
    "archivo_modelo = guardar_modelo_con_nombre(modelo_final, mejor_modelo['modelo'])\n",
    "\n",
    "n_estimators_catboost = None\n",
    "depth_catboost = None\n",
    "learning_rate_catboost = None\n",
    "n_estimators_rf = None\n",
    "n_estimators_xgb = None\n",
    "depth_xgb = None\n",
    "learning_rate_xgb = None\n",
    "\n",
    "if mejor_modelo['modelo'] == 'CatBoost':\n",
    "    n_estimators_catboost = modelo_final.named_steps['model'].get_params().get('iterations')\n",
    "    depth_catboost = modelo_final.named_steps['model'].get_params().get('depth')\n",
    "    learning_rate_catboost = modelo_final.named_steps['model'].get_params().get('learning_rate')\n",
    "elif mejor_modelo['modelo'] == 'Random Forest':\n",
    "    n_estimators_rf = modelo_final.named_steps['model'].get_params().get('n_estimators')\n",
    "elif mejor_modelo['modelo'] == 'XGBoost':\n",
    "    n_estimators_xgb = modelo_final.named_steps['model'].get_params().get('n_estimators')\n",
    "    depth_xgb = modelo_final.named_steps['model'].get_params().get('max_depth')\n",
    "    learning_rate_xgb = modelo_final.named_steps['model'].get_params().get('learning_rate')\n",
    "\n",
    "insertar_modelo(mejor_modelo['modelo'], accuracy, precision, recall, f1, roc_auc, tiempo_procesamiento, archivo_modelo, \n",
    "                n_estimators_catboost, depth_catboost, learning_rate_catboost, \n",
    "                n_estimators_rf, n_estimators_xgb, depth_xgb, learning_rate_xgb)\n",
    "\n",
    "print(f\"Modelo {mejor_modelo['modelo']} y sus parámetros han sido almacenados en la base de datos.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
