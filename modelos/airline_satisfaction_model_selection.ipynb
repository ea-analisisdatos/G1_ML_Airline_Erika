{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección del Mejor Modelo para el Proyecto F5 Airline (Tecnicas de Validación Cruzada y Ensemble Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código implementa un proceso completo de carga de datos, preprocesamiento, evaluación de modelos de machine learning, selección del mejor modelo, entrenamiento final con todos los datos, almacenamiento del modelo en disco, y finalmente inserción de las métricas y parámetros del modelo en una base de datos SQLite.\n",
    "\n",
    "También trabaja con Pipelines, y técnicas de Validación Cruzada y Ensemble Learning (StackingClassifier) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías principales para manipulación de datos\n",
    "import pandas as pd  # Manejo de datos en formato tabular (DataFrames)\n",
    "import numpy as np  # Funciones matemáticas y operaciones con arrays\n",
    "import sqlite3  # Para conectarse a la base de datos SQLite\n",
    "import os  # Para manejar el sistema de archivos\n",
    "import joblib  # Para guardar y cargar modelos entrenados\n",
    "from datetime import datetime, timedelta  # Para obtener la fecha y hora actual \n",
    "import time  # Para medir el tiempo de procesamiento\n",
    "\n",
    "# Librerías para construir pipelines y preprocesamiento\n",
    "from sklearn.pipeline import Pipeline  # Para crear pipelines que incluyan pasos de preprocesamiento y modelo\n",
    "from sklearn.preprocessing import StandardScaler  # Para escalar variables numéricas\n",
    "from sklearn.compose import ColumnTransformer  # Para aplicar diferentes transformaciones a diferentes tipos de columnas\n",
    "\n",
    "# Modelos de machine learning\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier  # Algoritmo de clasificación basado en árboles y Stacking (Técnica de Ensemble Learning)\n",
    "from catboost import CatBoostClassifier  # Algoritmo CatBoost, un modelo de boosting que maneja variables categóricas internamente\n",
    "from xgboost import XGBClassifier  # Algoritmo XGBoost, un modelo de boosting eficiente que tambien sirve para tratar variables categoricas\n",
    "\n",
    "# Librerías para validación cruzada y evaluación de modelos\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold  # Validación cruzada y división estratificada de los datos\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score  # Métricas para evaluar el rendimiento de los modelos\n",
    "\n",
    "# Configuración cuaderno Jupyter: Mostrar todas las columnas y ajustar ancho de las columnas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para Conectar con la Base de Datos\n",
    "- Objetivo: Establecer una conexión con la base de datos SQLite.\n",
    "- Razón: Los resultados de los modelos y sus parámetros serán almacenados en la base de datos para futuras consultas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para conectar a la base de datos SQLite\n",
    "def connect_db():\n",
    "    try:\n",
    "        conn = sqlite3.connect('../data/database/airline_satisfaction.db') # Conectar a la base de datos\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"Error al conectar a la base de datos: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para Crear y Insertar datos a la Tabla \"modelos_entrenados\" en SQLite\n",
    "- Objetivo: Crear una tabla en SQLite para almacenar la información de los modelos.\n",
    "- Razón: Facilitar el almacenamiento de las métricas y parámetros clave de cada modelo entrenado para su posterior consulta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 'modelos_entrenados' creada o ya existente.\n"
     ]
    }
   ],
   "source": [
    "# Función para crear la tabla de modelos entrenados si no existe en la base de datos\n",
    "def create_table():\n",
    "    conn = connect_db()\n",
    "    if conn:\n",
    "        try:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS modelos_entrenados (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                modelo TEXT,\n",
    "                accuracy_mean REAL,\n",
    "                precision_mean REAL,\n",
    "                recall_mean REAL,\n",
    "                f1_mean REAL,\n",
    "                roc_auc_mean REAL,\n",
    "                tiempo_procesamiento TEXT,\n",
    "                archivo_modelo TEXT,\n",
    "                n_estimators_catboost INTEGER,\n",
    "                depth_catboost INTEGER,\n",
    "                learning_rate_catboost REAL,\n",
    "                n_estimators_rf INTEGER,\n",
    "                n_estimators_xgb INTEGER,\n",
    "                depth_xgb INTEGER,\n",
    "                learning_rate_xgb REAL,\n",
    "                fecha_entrenamiento TEXT\n",
    "            )\n",
    "            ''')\n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "            print(\"Tabla 'modelos_entrenados' creada o ya existente.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al crear la tabla: {e}\")\n",
    "\n",
    "# Función para insertar un registro con el resultado del modelo en la base de datos\n",
    "def insertar_modelo(modelo_nombre, accuracy, precision, recall, f1, roc_auc, tiempo, archivo, \n",
    "                    n_estimators_catboost=None, depth_catboost=None, learning_rate_catboost=None, \n",
    "                    n_estimators_rf=None, n_estimators_xgb=None, depth_xgb=None, learning_rate_xgb=None):\n",
    "    conn = connect_db()\n",
    "    if conn:\n",
    "        try:\n",
    "            cursor = conn.cursor()\n",
    "            fecha_actual = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            cursor.execute('''\n",
    "                INSERT INTO modelos_entrenados \n",
    "                (modelo, accuracy_mean, precision_mean, recall_mean, f1_mean, roc_auc_mean, \n",
    "                tiempo_procesamiento, archivo_modelo, n_estimators_catboost, depth_catboost, \n",
    "                learning_rate_catboost, n_estimators_rf, n_estimators_xgb, depth_xgb, \n",
    "                learning_rate_xgb, fecha_entrenamiento)\n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            ''', (modelo_nombre, accuracy, precision, recall, f1, roc_auc, tiempo, archivo, \n",
    "                  n_estimators_catboost, depth_catboost, learning_rate_catboost, n_estimators_rf, \n",
    "                  n_estimators_xgb, depth_xgb, learning_rate_xgb, fecha_actual))\n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Error al insertar datos: {e}\")\n",
    "\n",
    "# Crear la tabla (si no existe) antes de comenzar la evaluación de modelos\n",
    "create_table()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de Datos y Preprocesamiento\n",
    "- Objetivo: Cargar y limpiar el dataset, eliminando valores nulos y columnas innecesarias.\n",
    "- Razón: Un preprocesamiento adecuado es esencial para que los modelos funcionen correctamente y no haya errores de inconsistencia en los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Cargar los datos (CSV original)\n",
    "data = pd.read_csv('../data/airline_passenger_satisfaction.csv')\n",
    "\n",
    "# Paso 1.1: Eliminar registros con valores nulos en la columna 'Arrival Delay in Minutes'\n",
    "data = data.dropna(subset=['Arrival Delay in Minutes'])\n",
    "\n",
    "# Paso 1.2: Eliminar las columnas 'Unnamed: 0' y 'id' porque no aportan valor al análisis y Machine Learning\n",
    "data = data.drop(['Unnamed: 0', 'id'], axis=1)\n",
    "\n",
    "# Paso 1.3: Convertir las etiquetas de 'satisfaction' de cadenas a valores numéricos (0 y 1)\n",
    "data['satisfaction'] = data['satisfaction'].map({'satisfied': 1, 'neutral or dissatisfied': 0})\n",
    "y = data['satisfaction']\n",
    "X = data.drop('satisfaction', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificación de Variables Categóricas\n",
    "- Objetivo: Convertir las variables categóricas en variables numéricas utilizando un mapeo manual.\n",
    "- Razón: Los algoritmos de machine learning generalmente no pueden trabajar directamente con datos categóricos, por lo que deben ser codificados numéricamente.\n",
    "\n",
    "---\n",
    "## <font color=#FF5733>¡Importante!</font>\n",
    "- Para las variables (columnas) numericas ordinales no ha sido necesario la tranformación categorica porque los valores ya son numéricos en estas variables y ya poseen una orden de 0 a 5.\n",
    "\n",
    "- Para evitar errores al comparar CatBoost con XGBoost y Random Forest, tuvimos que transformar las columnas categóricas usando una técnica llamada \"map\", en lugar de usar OneHotEncoder.\n",
    "\n",
    "    El problema surgía porque CatBoost maneja automáticamente las variables categóricas, mientras que XGBoost y Random Forest no lo hacen. Para estos dos > algoritmos, necesitábamos transformar las variables categóricas usando OneHotEncoder, lo que creaba columnas adicionales en el conjunto de datos. Esto causaba errores al comparar los modelos porque CatBoost no esperaba esas columnas adicionales en su proceso.\n",
    "\n",
    "    Para solucionar el problema y mantener la consistencia entre los modelos, decidimos usar el método \"map\" para codificar las variables categóricas en todos los algoritmos sin generar nuevas columnas. Esto permitió que el tamaño del conjunto de datos se mantuviera igual para los tres algoritmos y evitó los errores de comparación.\n",
    "\n",
    "    En resumen, usamos \"map\" para transformar las variables categóricas de forma que los datos se mantuvieran compatibles entre todos los algoritmos sin cambiar la estructura del dataset.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 2: Codificar manualmente las variables categóricas usando `map`\n",
    "categorical_cols = ['Gender', 'Customer Type', 'Type of Travel', 'Class']\n",
    "\n",
    "# Diccionarios de mapeo para convertir valores categóricos a numéricos\n",
    "categorical_mappings = {\n",
    "    'Gender': {'Male': 0, 'Female': 1},\n",
    "    'Customer Type': {'Loyal Customer': 1, 'disloyal Customer': 0},\n",
    "    'Type of Travel': {'Business travel': 1, 'Personal Travel': 0},\n",
    "    'Class': {'Eco': 0, 'Eco Plus': 1, 'Business': 2}\n",
    "}\n",
    "\n",
    "# Aplicar las transformaciones a las columnas categóricas\n",
    "for col, mapping in categorical_mappings.items():\n",
    "    X[col] = X[col].map(mapping)\n",
    "\n",
    "# Definir las columnas numéricas y ordinales\n",
    "ordinal_cols = ['Inflight wifi service', 'Departure/Arrival time convenient', 'Ease of Online booking', 'Gate location', \n",
    "                'Food and drink', 'Online boarding', 'Seat comfort', 'Inflight entertainment', 'On-board service', \n",
    "                'Leg room service', 'Baggage handling', 'Checkin service', 'Inflight service', 'Cleanliness']\n",
    "\n",
    "\n",
    "# Preprocesamiento: Escalar las columnas numéricas para los algoritmos que necesitan del escalado (CatBoost no necesita)\n",
    "numerical_cols = ['Age', 'Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes']\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración de Pipelines para Modelos individuales (RandomForestClassifier, XGBoost, y CatBoost)\n",
    "- Objetivo: Crear pipelines de preprocesamiento y modelado para facilitar la aplicación de transformaciones y entrenamiento de los modelos.\n",
    "- Razón: Los pipelines permiten una mayor modularidad y limpieza en la ejecución de tareas repetitivas, como el escalado y ajuste de modelos.\n",
    "\n",
    "Concepto Pipeline:\n",
    "- Un pipeline te permite encadenar varios pasos de preprocesamiento y el modelo de machine learning en una secuencia, asegurando que todos los pasos se ejecuten de manera consistente. Esto es útil cuando tienes que aplicar varias transformaciones (como la codificación de variables categóricas, imputación de valores nulos, etc.) antes de entrenar el modelo.\n",
    "- En este cuaderno luego abajo aplicamos el \"Escalado de las variables numéricas\" para los algoritmos que necesitan del escalado (CatBoost no necesita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 4: Crear los pipelines específicos de cada modelo\n",
    "pipeline_rf = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_xgb = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "pipeline_catboost = Pipeline(steps=[\n",
    "    ('model', CatBoostClassifier(iterations=100, depth=6, learning_rate=0.1, verbose=False))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Técnica de Ensemble Learning - StackingClassifier\n",
    "- Este es un paso importante porque estamos combinando múltiples modelos para mejorar el rendimiento.\n",
    "- Explicación: El StackingClassifier combina las predicciones de varios modelos base (CatBoost, XGBoost, RandomForest) y las pasa a un modelo meta (otro RandomForest en este caso). El objetivo es mejorar la precisión y la capacidad de generalización del modelo.\n",
    "\n",
    "¿Qué es el modelo de Stacking?\n",
    "El modelo de Stacking es un ensemble que combina las predicciones de varios modelos base (en este caso, Random Forest, XGBoost, y CatBoost) mediante un modelo final, que es conocido como meta-modelo. Este meta-modelo toma las predicciones de los modelos base y produce una predicción final más precisa.\n",
    "\n",
    "En este caso, el modelo que estamos guardando es el modelo completo de Stacking que utiliza estos tres modelos base y un Random Forest como meta-modelo para hacer la predicción final.\n",
    "\n",
    "¿Qué ocurre con los modelos individuales?\n",
    "El código actual evalúa el rendimiento de cada modelo individual (Random Forest, XGBoost, y CatBoost) y también evalúa el modelo de Stacking. Los resultados se almacenan en un DataFrame y se imprimen, pero no estamos seleccionando automáticamente el modelo individual con mejor rendimiento para guardarlo por separado. Actualmente, solo se guarda el modelo de Stacking completo, independientemente de si este tiene el mejor rendimiento en comparación con los modelos individuales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de Stacking que combina los tres modelos anteriores\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('catboost', pipeline_catboost),\n",
    "        ('xgboost', pipeline_xgb),\n",
    "        ('random_forest', pipeline_rf)\n",
    "    ],\n",
    "    final_estimator=RandomForestClassifier(n_estimators=50, random_state=42), # Meta-modelo: Random Forest\n",
    "    cv=5 # Validación cruzada 5 pligues\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación y Validación Cruzada\n",
    "- Objetivo: Evaluar cada modelo utilizando validación cruzada estratificada y calcular el tiempo de procesamiento.\n",
    "- Razón: La validación cruzada permite obtener una estimación más robusta del rendimiento del modelo, y medir el tiempo ayuda a tener en cuenta la eficiencia de cada algoritmo.\n",
    "\n",
    "- Concepto Validación Cruzada:\n",
    "La validación cruzada es una técnica usada en machine learning para evaluar el rendimiento de un modelo de manera más robusta. En lugar de entrenar y probar el modelo una sola vez dividiendo los datos en un conjunto de entrenamiento y otro de prueba, la validación cruzada divide los datos en varios subconjuntos y realiza múltiples ciclos de entrenamiento y prueba, lo que permite obtener una evaluación más estable y evitar sobreajuste (overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluando Random Forest...\n",
      "\n",
      "Evaluando XGBoost...\n",
      "\n",
      "Evaluando CatBoost...\n",
      "\n",
      "Evaluando Stacking...\n"
     ]
    }
   ],
   "source": [
    "# Definir las métricas de evaluación\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "# Función para evaluar el modelo con tiempo de procesamiento\n",
    "def evaluar_modelo_con_tiempo(pipeline, X, y, cv):\n",
    "    start_time = time.time()\n",
    "    cv_results = cross_validate(pipeline, X, y, cv=cv, scoring=scoring, return_train_score=False)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_time_readable = str(timedelta(seconds=elapsed_time))\n",
    "    \n",
    "    return cv_results, elapsed_time, elapsed_time_readable\n",
    "\n",
    "# Definir el KFold estratificado para la validación cruzada\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Lista para almacenar los resultados de los modelos\n",
    "resultados = []\n",
    "\n",
    "# Diccionario con los modelos que vamos a evaluar\n",
    "modelos = {\n",
    "    'Random Forest': pipeline_rf,\n",
    "    'XGBoost': pipeline_xgb,\n",
    "    'CatBoost': pipeline_catboost,\n",
    "    'Stacking': stacking_model\n",
    "}\n",
    "\n",
    "# Evaluar cada modelo con validación cruzada y almacenar los resultados\n",
    "for nombre_modelo, modelo in modelos.items():\n",
    "    print(f\"\\nEvaluando {nombre_modelo}...\")\n",
    "    cv_resultados, tiempo, tiempo_legible = evaluar_modelo_con_tiempo(modelo, X, y, kf)\n",
    "    \n",
    "    # Almacena los resultados en el diccionario\n",
    "    resultados.append({\n",
    "        'modelo': nombre_modelo,\n",
    "        'accuracy_mean': cv_resultados['test_accuracy'].mean(),\n",
    "        'precision_mean': cv_resultados['test_precision'].mean(),\n",
    "        'recall_mean': cv_resultados['test_recall'].mean(),\n",
    "        'f1_mean': cv_resultados['test_f1'].mean(),\n",
    "        'roc_auc_mean': cv_resultados['test_roc_auc'].mean(),\n",
    "        'tiempo_procesamiento': tiempo,\n",
    "        'tiempo_procesamiento_legible': tiempo_legible,\n",
    "        'modelo_pipeline': modelo\n",
    "    })\n",
    "\n",
    "# Crear un DataFrame con los resultados y mostrarlo\n",
    "df_resultados = pd.DataFrame(resultados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección del Mejor Modelo y Almacenamiento\n",
    "- Objetivo: Seleccionar el modelo con el mejor rendimiento en función de la métrica de accuracy.\n",
    "- Razón: Este paso es clave para escoger el modelo que mejor se adapte a los datos, basándose en las métricas de evaluación seleccionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados finales:\n",
      "+----+---------------+-----------------+------------------+---------------+-----------+----------------+------------------------+--------------------------------+\n",
      "|    | modelo        |   accuracy_mean |   precision_mean |   recall_mean |   f1_mean |   roc_auc_mean |   tiempo_procesamiento | tiempo_procesamiento_legible   |\n",
      "|----+---------------+-----------------+------------------+---------------+-----------+----------------+------------------------+--------------------------------|\n",
      "|  0 | Random Forest |        0.632373 |         0.583962 |      0.527764 |  0.55444  |       0.620075 |              136.41    | 0:02:16.410275                 |\n",
      "|  1 | XGBoost       |        0.677925 |         0.674597 |      0.496225 |  0.571813 |       0.656566 |                4.33325 | 0:00:04.333248                 |\n",
      "|  2 | CatBoost      |        0.960191 |         0.968753 |      0.938415 |  0.953341 |       0.957631 |               17.6212  | 0:00:17.621177                 |\n",
      "|  3 | Stacking      |        0.957044 |         0.962776 |      0.937123 |  0.949772 |       0.954702 |              889.611   | 0:14:49.610507                 |\n",
      "+----+---------------+-----------------+------------------+---------------+-----------+----------------+------------------------+--------------------------------+\n",
      "\n",
      "Los resultados completos se han guardado en el archivo: ../data/modelos_entrenamiento/resultados_modelos_completos.csv\n",
      "\n",
      "El mejor modelo ha sido: CatBoost debido a su mejor rendimiento en accuracy de 0.9602\n",
      "\n",
      "Entrenando el mejor modelo: CatBoost con todos los datos...\n"
     ]
    }
   ],
   "source": [
    "# Eliminar la columna 'modelo_pipeline' para una mejor visualización en consola\n",
    "df_vista_consola = df_resultados.drop(columns=['modelo_pipeline'])\n",
    "\n",
    "# Mostrar los resultados finales en la consola\n",
    "print(\"\\nResultados finales:\")\n",
    "print(tabulate(df_vista_consola, headers='keys', tablefmt='psql'))\n",
    "\n",
    "# Guardar los resultados en un archivo CSV\n",
    "output_csv = '../data/modelos_entrenamiento/resultados_modelos_completos.csv'\n",
    "df_resultados.to_csv(output_csv, index=False)\n",
    "print(f\"\\nLos resultados completos se han guardado en el archivo: {output_csv}\")\n",
    "\n",
    "# Identificar el mejor modelo basado en el accuracy\n",
    "mejor_modelo = df_resultados.loc[df_resultados['accuracy_mean'].idxmax()] # Obtener el mejor modelo basado en la precisión\n",
    "\n",
    "print(f\"\\nEl mejor modelo ha sido: {mejor_modelo['modelo']} debido a su mejor rendimiento en accuracy de {mejor_modelo['accuracy_mean']:.4f}\")\n",
    "print(f\"\\nEntrenando el mejor modelo: {mejor_modelo['modelo']} con todos los datos...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento Final, Almacenamiento del Mejor Modelo y Registro de sus Parámetros\n",
    "- Objetivo: Entrenar el mejor modelo y guardarlo en disco y registrar sus parámetros en la base de datos SQLite.\n",
    "- Razón: Guardar el modelo permite reutilizarlo en el futuro sin necesidad de volver a entrenarlo, mientras que almacenar sus métricas y parámetros facilita el seguimiento del rendimiento de los modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo CatBoost guardado exitosamente con el nombre: CatBoost_mejor_modelo_20240910_123529.cbm\n",
      "Modelo CatBoost y sus parámetros han sido almacenados en la base de datos.\n"
     ]
    }
   ],
   "source": [
    "# Finalmente, entrenamos el modelo con todos los datos y lo almacenamos en el sistema de archivos. También guardamos sus parámetros y métricas en la base de datos.\n",
    "modelo_final = mejor_modelo['modelo_pipeline'] # Extraer el pipeline del mejor modelo\n",
    "modelo_final.fit(X, y) # Entrenar el modelo final con todos los datos\n",
    "\n",
    "accuracy = mejor_modelo['accuracy_mean']\n",
    "precision = mejor_modelo['precision_mean']\n",
    "recall = mejor_modelo['recall_mean']\n",
    "f1 = mejor_modelo['f1_mean']\n",
    "roc_auc = mejor_modelo['roc_auc_mean']\n",
    "tiempo_procesamiento = mejor_modelo['tiempo_procesamiento_legible']\n",
    "archivo_modelo = \"\" # Inicializar el nombre del archivo para guardar el modelo\n",
    "\n",
    "# Función para guardar el modelo con un nombre apropiado\n",
    "def guardar_modelo_con_nombre(modelo, nombre_modelo):\n",
    "    output_dir = '../data/modelos_entrenamiento/' # Directorio donde se guardarán los modelos\n",
    "    os.makedirs(output_dir, exist_ok=True) # Crear el directorio si no existe\n",
    "    \n",
    "    fecha_hora_actual = datetime.now().strftime('%Y%m%d_%H%M%S') # Obtener la fecha y hora actual\n",
    "    \n",
    "    if nombre_modelo == 'CatBoost':\n",
    "        archivo_modelo = f\"{nombre_modelo}_mejor_modelo_{fecha_hora_actual}.cbm\"  # Guardar en formato específico de CatBoost\n",
    "        modelo.named_steps['model'].save_model(os.path.join(output_dir, archivo_modelo)) # Guardar el modelo de CatBoost\n",
    "        print(f\"Modelo CatBoost guardado exitosamente con el nombre: {archivo_modelo}\")\n",
    "    else:\n",
    "        archivo_modelo = f\"{nombre_modelo}_mejor_modelo_{fecha_hora_actual}.pkl\" # Guardar en formato pickle\n",
    "        joblib.dump(modelo, os.path.join(output_dir, archivo_modelo)) # Guardar el modelo con joblib    \n",
    "        print(f\"Modelo guardado exitosamente con el nombre: {archivo_modelo}\")\n",
    "    \n",
    "    return archivo_modelo # Retornar el nombre del archivo guardado\n",
    "\n",
    "# Guardar el mejor modelo y obtener el nombre del archivo\n",
    "archivo_modelo = guardar_modelo_con_nombre(modelo_final, mejor_modelo['modelo'])\n",
    "\n",
    "# Inicializar parámetros específicos para los diferentes modelos\n",
    "n_estimators_catboost = None\n",
    "depth_catboost = None\n",
    "learning_rate_catboost = None\n",
    "n_estimators_rf = None\n",
    "n_estimators_xgb = None\n",
    "depth_xgb = None\n",
    "learning_rate_xgb = None\n",
    "\n",
    "# Obtener los parámetros relevantes del mejor modelo\n",
    "if mejor_modelo['modelo'] == 'CatBoost':\n",
    "    n_estimators_catboost = modelo_final.named_steps['model'].get_params().get('iterations')\n",
    "    depth_catboost = modelo_final.named_steps['model'].get_params().get('depth')\n",
    "    learning_rate_catboost = modelo_final.named_steps['model'].get_params().get('learning_rate')\n",
    "elif mejor_modelo['modelo'] == 'Random Forest':\n",
    "    n_estimators_rf = modelo_final.named_steps['model'].get_params().get('n_estimators')\n",
    "elif mejor_modelo['modelo'] == 'XGBoost':\n",
    "    n_estimators_xgb = modelo_final.named_steps['model'].get_params().get('n_estimators')\n",
    "    depth_xgb = modelo_final.named_steps['model'].get_params().get('max_depth')\n",
    "    learning_rate_xgb = modelo_final.named_steps['model'].get_params().get('learning_rate')\n",
    "\n",
    "# Insertar los resultados y parámetros del mejor modelo en la base de datos\n",
    "insertar_modelo(mejor_modelo['modelo'], accuracy, precision, recall, f1, roc_auc, tiempo_procesamiento, archivo_modelo, \n",
    "                n_estimators_catboost, depth_catboost, learning_rate_catboost, \n",
    "                n_estimators_rf, n_estimators_xgb, depth_xgb, learning_rate_xgb)\n",
    "\n",
    "# Mensaje final indicando que el modelo y sus parámetros han sido almacenados en la base de datos\n",
    "print(f\"Modelo {mejor_modelo['modelo']} y sus parámetros han sido almacenados en la base de datos.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
